{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleGAN-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVVTfW5qupbrItm0OpRdy5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/GAN-Webinars/blob/main/SimpleGAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yUJTjI6J4k6"
      },
      "source": [
        "#  In The Name Of ALLAH\n",
        "#  Generative Adversarial Networks\n",
        "#  PythonChallenge.ir\n",
        "#  Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "#  Lecture 0 - Simple GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Ig-6fhKTxR"
      },
      "source": [
        "In this lecture, we're going to implement a very simple GAN to generate some digits. We're focusing on the main concept of GANs, not the network architectures. So would use fully-connected networks (MLP) as the discriminator and generator structure. Let' see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLtuDessS6Q5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, InputLayer, Reshape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmJUJvyYK7Pz"
      },
      "source": [
        "#  Dataset Preparation\n",
        "We would use the famous **MNIST** dataset for handwritten digits. Let's assume we just want to generate a specific digit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpxssF_sTImR"
      },
      "source": [
        "(Xtrain, ytrain), (Xtest, ytest) = mnist.load_data()\n",
        "Xtrain = Xtrain[ytrain==7]\n",
        "ytrain = ytrain[ytrain==7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19RV9RRALeir"
      },
      "source": [
        "#  Visualization\n",
        "In order to visualize results, we would implement ```show``` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvv-A31gtU7b"
      },
      "source": [
        "def show(X, r=4, c=4):\n",
        "  fig, ax = plt.subplots(r, c, True, True)\n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      ax[i][j].imshow(X[i * c + j])\n",
        "  plt.show()\n",
        "\n",
        "show(Xtrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we6DsTrHeKon"
      },
      "source": [
        "We determine image shapes and the our noise dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSjUIdG6Thp-"
      },
      "source": [
        "img_shape = 28, 28\n",
        "z_dim = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhGBhoQ2eTsJ"
      },
      "source": [
        "#  Discriminator\n",
        "Let's build **discriminator** now. We use an MLP as the discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkH9FJKmTb-N"
      },
      "source": [
        "def buildDisc(img_shape=(28, 28)):\n",
        "  model = Sequential()\n",
        "  model.add(InputLayer(img_shape))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation='elu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "disc = buildDisc()\n",
        "disc.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r6MdziNlaml"
      },
      "source": [
        "# Generator\n",
        "Again, we use an MLP for the generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irN6OU3ZineQ"
      },
      "source": [
        "def buildGen(img_shape=(28, 28), z_dim=100):\n",
        "  model = Sequential()\n",
        "  model.add(InputLayer((z_dim,)))\n",
        "  model.add(Dense(64, 'elu'))\n",
        "  model.add(Dense(img_shape[0]*img_shape[1], 'sigmoid'))\n",
        "  model.add(Reshape(img_shape))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lACPXl_2LTR"
      },
      "source": [
        "gen = buildGen()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrGi84fOelXU"
      },
      "source": [
        "#  GAN\n",
        "Time to build a model for **GAN**. We build it by cascading the generator and the discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMUD7Kjejz5G"
      },
      "source": [
        "def buildGan(disc, gen):\n",
        "  model = Sequential()\n",
        "  model.add(gen)\n",
        "  model.add(disc)\n",
        "  return model\n",
        "\n",
        "disc.trainable = False\n",
        "gan = buildGan(disc, gen)\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1urtXngHmIPC"
      },
      "source": [
        "#  Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzb2V5FHhl0d"
      },
      "source": [
        "for i in range(1000):\r\n",
        "  indxs = np.random.permutation(len(Xtrain))[:16]\r\n",
        "  Xreal = Xtrain[indxs]\r\n",
        "  yreal = np.ones((16,))\r\n",
        "  noise = np.random.normal(0, 1, size=(16, z_dim))\r\n",
        "  Xfake = gen.predict(noise)\r\n",
        "  yfake = np.zeros_like(yreal)\r\n",
        "\r\n",
        "  ##  Disc. Training\r\n",
        "  d_loss_real = disc.train_on_batch(Xreal, yreal)\r\n",
        "  d_loss_fake = disc.train_on_batch(Xfake, yfake)\r\n",
        "  d_loss, d_acc = np.add(d_loss_real, d_loss_fake) / 2\r\n",
        "\r\n",
        "  ##  Gen. Training\r\n",
        "  noise = np.random.normal(0, 1, size=(16, z_dim))\r\n",
        "  g_loss = gan.train_on_batch(noise, yreal)\r\n",
        "\r\n",
        "  if not ((i+1)%20):\r\n",
        "    print(f'No {i + 1}\\tD Acc: {d_acc}\\tD Loss: {d_loss}\\tG Loss: {g_loss}')\r\n",
        "    Xfake = gen.predict(noise)\r\n",
        "    show(Xfake)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}