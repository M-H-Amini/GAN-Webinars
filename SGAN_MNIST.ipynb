{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGAN-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLIhrKVXW3DBv8/WvJxs4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/GAN-Webinars/blob/main/SGAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a5GcG5OpVGe"
      },
      "source": [
        "#  In The Name Of ALLAH\n",
        "#  Generative Adversarial Networks\n",
        "#  PythonChallenge.ir\n",
        "#  Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "#  Lecture 2 - SGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VUsaRxXUrOQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Flatten, Reshape, Dense, Dropout, Activation, Lambda\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVoYHPJ3VAEe"
      },
      "source": [
        "class MHDS:\n",
        "  def __init__(self, n_labeled=200, n_unlabeled=None):\n",
        "    (self.Xtrain, self.ytrain), (self.Xtest, self.ytest) = mnist.load_data()\n",
        "    self.Xtrain, self.ytrain = shuffle(self.Xtrain, self.ytrain, random_state=0)\n",
        "\n",
        "    self.n_labeled = n_labeled \n",
        "    if n_unlabeled is not None:\n",
        "      self.n_unlabeled = n_unlabeled\n",
        "    else:\n",
        "      self.n_unlabeled = len(self.Xtrain) - n_labeled\n",
        "    \n",
        "    self.Xtrain = np.expand_dims((self.Xtrain - 127.5) / 127.5, -1)\n",
        "    self.Xtest = np.expand_dims((self.Xtest - 127.5) / 127.5, -1)\n",
        "\n",
        "    self.X_sup = self.Xtrain[:n_labeled]\n",
        "    self.y_sup = self.ytrain[:n_labeled]\n",
        "\n",
        "    self.X_unsup = self.Xtrain[n_labeled:n_labeled+self.n_unlabeled]\n",
        "\n",
        "  def batchSupervised(self, batch_size=32):\n",
        "    index = np.random.permutation(self.n_labeled)[:batch_size]\n",
        "    return self.X_sup[index], self.y_sup[index]\n",
        "  \n",
        "  def batchUnsupervised(self, batch_size=32):\n",
        "    index = np.random.permutation(self.n_unlabeled)[:batch_size]\n",
        "    return self.X_unsup[index]\n",
        "\n",
        "mhds = MHDS()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLldzChpXG6-"
      },
      "source": [
        "def show(X, y=None, r=4, c=4):\n",
        "  fig, ax = plt.subplots(r, c, True, True, figsize=(8,8))\n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      ax[i][j].imshow(X[i*c + j, :, :, 0])\n",
        "      if y is not None:\n",
        "        ax[i][j].set_title(str(y[i*c + j]))\n",
        "  plt.show()\n",
        "\n",
        "# show(mhds.batchUnsupervised())\n",
        "show(*mhds.batchSupervised())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8zQHdcDX6j-"
      },
      "source": [
        "def buildDisc(img_shape=(28, 28, 1), k=10):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, 3, 2, 'same', input_shape=img_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(0.01))\n",
        "  \n",
        "  model.add(Conv2D(64, 3, 2, 'same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(0.01))\n",
        "  \n",
        "  model.add(Conv2D(128, 3, 2, 'same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(0.01))\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(k))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhHC0Ha9ZElS"
      },
      "source": [
        "def buildSupervisedDisc(disc):\n",
        "  model = Sequential()\n",
        "  model.add(disc)\n",
        "  model.add(Activation('softmax'))\n",
        "  return model\n",
        "\n",
        "def buildUnsupervisedDisc(disc):\n",
        "  model = Sequential()\n",
        "  model.add(disc)\n",
        "  \n",
        "  def predict(x):\n",
        "    p = 1. - 1./(K.sum(K.exp(x), keepdims=True, axis=-1) + 1.)\n",
        "    return p\n",
        "  \n",
        "  model.add(Lambda(predict))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHrmUdIEaDfS"
      },
      "source": [
        "disc = buildDisc()\n",
        "disc_sup = buildSupervisedDisc(disc)\n",
        "disc_unsup = buildUnsupervisedDisc(disc)\n",
        "disc_sup.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "disc_unsup.compile(optimizer='adam', loss='bce', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7--EaLJTabPL"
      },
      "source": [
        "def buildGen(z_dim=100):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(7*7*256, input_shape=(z_dim,)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Reshape((7, 7, 256)))\n",
        "  \n",
        "  model.add(Conv2DTranspose(128, 3, 2, 'same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(0.01))\n",
        "  \n",
        "  model.add(Conv2DTranspose(64, 3, 2, 'same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(0.01))\n",
        "\n",
        "  model.add(Conv2DTranspose(1, 3, 1, 'same', activation='tanh'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4glAwta7bPEn"
      },
      "source": [
        "def buildGan(disc, gen):\n",
        "  return Sequential([gen, disc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXjvKHw9bdlU"
      },
      "source": [
        "gen = buildGen()\n",
        "\n",
        "disc_unsup.trainable = False\n",
        "gan = buildGan(disc_unsup, gen)\n",
        "gan.compile(optimizer='adam', loss='bce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irwwNMFob7cV"
      },
      "source": [
        "def train(iterations=2000, batch_size=32):\n",
        "  for i in range(iterations):\n",
        "    Xsup, ysup = mhds.batchSupervised(batch_size)\n",
        "    Xunsup = mhds.batchUnsupervised(batch_size)\n",
        "    noise = np.random.randn(batch_size, 100)\n",
        "    Xfake = gen.predict(noise)\n",
        "    ones = np.ones((batch_size, 1))\n",
        "    zeros = np.zeros((batch_size, 1))\n",
        "\n",
        "\n",
        "    ##  Supervised Training\n",
        "    loss_sup, acc_sup = disc_sup.train_on_batch(Xsup, ysup)\n",
        "\n",
        "    ##  Unsupervised Training\n",
        "    loss_unsup_real = disc_unsup.train_on_batch(Xunsup, ones)\n",
        "    loss_unsup_fake = disc_unsup.train_on_batch(Xunsup, zeros)\n",
        "\n",
        "    loss_unsup, acc_unsup = 0.5 * np.add(loss_unsup_real, loss_unsup_fake)\n",
        "\n",
        "    ##  Generator Training\n",
        "    noise = np.random.randn(batch_size, 100)\n",
        "    gan.train_on_batch(noise, ones)\n",
        "\n",
        "    if not(i%100):\n",
        "      test_loss, test_acc = disc_sup.evaluate(mhds.Xtest, mhds.ytest)\n",
        "      print(f'Iteration {i}:\\tLoss supervised={loss_sup:4.2f}\\tAcc supervised={acc_sup:4.2f}\\t Loss Unsupervised={loss_unsup:4.2f}')\n",
        "      print(f'Loss Test: {test_loss:4.2f}\\tAcc Test:{test_acc:4.2f}')\n",
        "\n",
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2FW95SRdq04"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}